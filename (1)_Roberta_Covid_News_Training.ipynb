{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(1) Roberta-Covid-News-Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZqZHCAxnxN1N2Xr9JK20J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Halifaxi/Covid-Reproducible/blob/main/(1)_Roberta_Covid_News_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FrDqeMtkAxh",
        "outputId": "076b5cd0-6ad5-4375-afaf-2b8dcd409da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install transformers; "
      ],
      "metadata": {
        "id": "mOuelroZeFFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da1aa6d-a1a3-4bd6-9bad-9fdc87ea659c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.4.0\n",
            "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4 MB 6.8 kB/s \n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.4.0\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 12.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 36.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1SIIeg945ZQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "78Ub7K4beM6K",
        "outputId": "192af60c-116b-4e58-f77f-922c09aa96b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.4.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku054jaB9kGL",
        "outputId": "2a05e52e-45fa-499a-8126-64f9584ae8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "4ORiMr_ychgv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/covid_annotations.csv')"
      ],
      "metadata": {
        "id": "93FxWifuBpxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.Label.value_counts())\n",
        "neg_to_pos = df.Label.value_counts()[0] / df.Label.value_counts().sum()\n",
        "print(f'Proportion of negative samples in the dataset = {np.around(neg_to_pos,3)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L4yhXdsgpKO",
        "outputId": "7e9e7ff0-54d5-47d2-8b7e-08e03100a643"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    556\n",
            "1    436\n",
            "Name: Label, dtype: int64\n",
            "Proportion of negative samples in the dataset = 0.56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnuY_DB-9DKR",
        "outputId": "291c55fa-226a-4b3e-edd5-a15634657523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "992"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text):\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub('\\n','',text).strip()\n",
        "    text = re.sub('we\\'ll','we will',text, flags=re.IGNORECASE)\n",
        "    text = re.sub('didn\\'t','did not',text, flags=re.IGNORECASE)\n",
        "    text = re.sub('don\\'t','do not',text, flags=re.IGNORECASE)\n",
        "    text = re.sub('aren\\'t','are not',text, flags=re.IGNORECASE)\n",
        "    text = re.sub('doesn\\'t','does not',text, flags=re.IGNORECASE)\n",
        "    text = re.sub('what\\'s','what is',text, flags=re.IGNORECASE)\n",
        "    text = re.sub('it\\'s','it is',text, flags=re.IGNORECASE)\n",
        "    text = re.sub('that\\'s','that is',text, flags=re.IGNORECASE)\n",
        "    text = re.sub('he\\'s','he is',text, flags=re.IGNORECASE)\n",
        "    text = re.sub('she\\'s','she is',text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'coronavirus', 'covid', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'covid-19', 'covid', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'sars-cov-2', 'covid', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    text = text + '.' if text and text[-1] not in ('.', '!', '?') else text\n",
        "    return text\n",
        "df.Sentence = df.Sentence.apply(text_preprocessing)"
      ],
      "metadata": {
        "id": "GLR7uaVLr1Dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L1_SSDAxFvWT",
        "outputId": "b9b60401-c95f-4cde-f87a-5d7ba00369d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Sentence  Label\n",
              "0  Countys milestone comes after it hit 4,000 dea...      0\n",
              "1  Riverside Countys covid death toll surpassed 5...      0\n",
              "2  Numbers posted on the countys covid website Fr...      0\n",
              "3  Our county team continues to work diligently t...      1\n",
              "4  Orange County , which has about 700,000 more p...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8c0cf6e-d9cf-43f9-bffb-e268312a31f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Countys milestone comes after it hit 4,000 dea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Riverside Countys covid death toll surpassed 5...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Numbers posted on the countys covid website Fr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Our county team continues to work diligently t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Orange County , which has about 700,000 more p...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8c0cf6e-d9cf-43f9-bffb-e268312a31f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8c0cf6e-d9cf-43f9-bffb-e268312a31f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8c0cf6e-d9cf-43f9-bffb-e268312a31f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regular roberta training"
      ],
      "metadata": {
        "id": "6oe8lseYc5QY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0oON6Xw5M7m",
        "outputId": "b4c6718f-e165-4f1b-8bad-6539d7958934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing step"
      ],
      "metadata": {
        "id": "PvkhAVeb-BPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "model_name = \"siebert/sentiment-roberta-large-english\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name, truncation=True)"
      ],
      "metadata": {
        "id": "2rEfigomeWM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I believe what I did is install the newer Roberta model on an updated version of PyTorch and then I saved it using _use_new_zipfile_serialization=False. Which I then could open using regular PyTorch."
      ],
      "metadata": {
        "id": "QN2CghGVGAcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  model = RobertaModel.from_pretrained(model_name, map_location=device)\n",
        "# torch.save(model, f = '/content/drive/MyDrive/base_old_torch_rob.pth', _use_new_zipfile_serialization=False)\n",
        "model = torch.load('/content/drive/MyDrive/base_old_torch_rob.pth')\n",
        "# torch.save(model.state_dict(),f = '/content/drive/MyDrive/covid_TEST.pth' ,_use_new_zipfile_serialization=False)"
      ],
      "metadata": {
        "id": "OWRj_ukmuhpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentData(Dataset):\n",
        "    \"\"\"Converts pandas dataframe into usable input for pytorch\n",
        "\n",
        "    Params:\n",
        "            dataframe, tokenizer, Max_len\n",
        "    \n",
        "    Returns:\n",
        "            'ids',\n",
        "            'mask',\n",
        "            'token_type_ids',\n",
        "            'targets',\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.Sentence\n",
        "        self.targets = self.data.Label\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=MAX_LEN,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            )\n",
        "        \n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ],
      "metadata": {
        "id": "QoLvp7oiHoYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate train data and test data\n",
        "all_text = df.Sentence.values\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_text = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_text]\n",
        "\n",
        "# Find the maximum length\n",
        "MAX_LEN = max([len(sent) for sent in encoded_text])\n",
        "print('Max length: ', MAX_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4Aaadn2OfPl",
        "outputId": "1c777c4e-c200-492a-d865-de1fb6ffed13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max length:  109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.95\n",
        "train_data= df.sample(frac=train_size,random_state=42)\n",
        "test_data= df.drop(train_data.index).reset_index(drop=True)\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
        "\n",
        "training_set = SentimentData(train_data, tokenizer, MAX_LEN)\n",
        "testing_set = SentimentData(test_data, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM4NY0eNNRoX",
        "outputId": "f63817ed-148a-4381-9d5c-fd1b82398d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (992, 2)\n",
            "TRAIN Dataset: (942, 2)\n",
            "TEST Dataset: (50, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_BATCH_SIZE = 5\n",
        "VALID_BATCH_SIZE = 5\n",
        "LEARNING_RATE = 1e-05\n",
        "\n",
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "t8ChrpgrPteS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RobertaClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaClassifier, self).__init__()\n",
        "        # self.l1 = RobertaModel.from_pretrained(\"/content/drive/MyDrive/pre_trained_roberta_model_base\") # Save it locally for faster import time.\n",
        "        # self.l1 = RobertaModel.from_pretrained(\"siebert/sentiment-roberta-large-english\")\n",
        "        self.l1 = torch.load('/content/drive/MyDrive/base_old_torch_rob.pth') #PLEASE\n",
        "        self.pre_classifier = torch.nn.Linear(1024, 1024)\n",
        "        self.dropout = torch.nn.Dropout(0.18)\n",
        "        self.classifier = torch.nn.Linear(1024, 2)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output\n",
        "        "
      ],
      "metadata": {
        "id": "f0X6Qqg-XhKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaClassifier().to(device);\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/covid_checkpoint.pth', map_location=device))"
      ],
      "metadata": {
        "id": "n37HMDhOX_iV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8e8eac-e12c-4a65-87b8-f0ee24c648a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'transformers.models.roberta.modeling_roberta.RobertaModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.normalization.LayerNorm' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'transformers.models.roberta.modeling_roberta.RobertaSelfAttention' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning and Training the Model"
      ],
      "metadata": {
        "id": "_3SrrGqo-4Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcuate_accuracy(preds, targets):\n",
        "    n_correct = (preds==targets).sum().item()\n",
        "    return n_correct\n",
        "# Creating the loss function and optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "zApngqOjz4X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        mask = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        loss = loss_function(outputs, targets)\n",
        "        tr_loss += loss.item()\n",
        "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += calcuate_accuracy(big_idx, targets)\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples+=targets.size(0)\n",
        "        \n",
        "        if _%5000==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            accu_step = (n_correct*100)/nb_tr_examples \n",
        "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
        "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return "
      ],
      "metadata": {
        "id": "ZpR0Pmes7rfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "EPOCHS = 2\n",
        "for epoch in range(EPOCHS):\n",
        "    train(epoch)"
      ],
      "metadata": {
        "id": "LacQhQ8c7ros",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f28fd3f-c0d7-4934-d0b4-6a1a0611fcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss per 5000 steps: 0.5505173206329346\n",
            "Training Accuracy per 5000 steps: 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "189it [01:28,  2.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Total Accuracy for Epoch 0: 86.94267515923566\n",
            "Training Loss Epoch: 0.43486682048915004\n",
            "Training Accuracy Epoch: 86.94267515923566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss per 5000 steps: 0.08309106528759003\n",
            "Training Accuracy per 5000 steps: 100.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "189it [01:28,  2.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Total Accuracy for Epoch 1: 95.01061571125265\n",
            "Training Loss Epoch: 0.24295600312860516\n",
            "Training Accuracy Epoch: 95.01061571125265\n",
            "CPU times: user 2min 24s, sys: 22.7 s, total: 2min 47s\n",
            "Wall time: 2min 57s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Validation"
      ],
      "metadata": {
        "id": "YBbeZVpc0q81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    model.eval()\n",
        "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
        "    with torch.no_grad(): \n",
        "        for num, data in tqdm(enumerate(testing_loader)):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.long)\n",
        "            \n",
        "            # outputs = model(ids, mask, token_type_ids).squeeze()\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            loss = loss_function(outputs, targets)\n",
        "            tr_loss += loss.item()\n",
        "            big_val, big_idx = torch.max(outputs.data, dim=1) # This for prediction and score. \n",
        "            n_correct += calcuate_accuracy(big_idx, targets) \n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples+=targets.size(0)\n",
        "            \n",
        "            if num%5000==0:\n",
        "                loss_step = tr_loss/nb_tr_steps\n",
        "                accu_step = (n_correct*100)/nb_tr_examples\n",
        "                print(f\"\\n Validation Loss per 100 steps: {loss_step}\")\n",
        "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
        "\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
        "    \n",
        "    return epoch_accu\n"
      ],
      "metadata": {
        "id": "jIkARqB-0rVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "acc = valid(model, testing_loader)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fESXT8gx0vev",
        "outputId": "2bf755e0-054e-49c0-9872-458987b0ce10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2it [00:00,  6.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss per 100 steps: 1.1860120296478271\n",
            "Validation Accuracy per 100 steps: 80.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "10it [00:01,  8.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Epoch: 0.12521915442775935\n",
            "Validation Accuracy Epoch: 98.0\n",
            "Accuracy on test data = 98.00%\n",
            "CPU times: user 1.19 s, sys: 7.07 ms, total: 1.2 s\n",
            "Wall time: 1.21 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classes = 2\n",
        "wrong_preds = []\n",
        "# Initialize the prediction and label lists(tensors)\n",
        "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "model.eval()\n",
        "how_confident = []\n",
        "with torch.no_grad():      \n",
        "    for i, data in enumerate(testing_loader):\n",
        "            ids = data['ids'].to(device, dtype = torch.long)\n",
        "            mask = data['mask'].to(device, dtype = torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "            targets = data['targets'].to(device, dtype = torch.long)\n",
        "            # outputs = model(ids, mask, token_type_ids) # REGULAR\n",
        "            outputs = F.softmax(model(ids, mask, token_type_ids), dim=-1) # SOFTMAX\n",
        "            scores, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Append batch prediction results\n",
        "            predlist = torch.cat([predlist,preds.view(-1).cpu()])\n",
        "            lbllist = torch.cat([lbllist,targets.view(-1).cpu()])\n",
        "            how_confident.append(np.mean(scores.cpu().numpy()))\n",
        "\n",
        "            # keep track of the predictions when the model goes wrong.\n",
        "            idx_wrong_predictions = np.where(preds.view(-1).cpu() != targets.view(-1).cpu())[0]\n",
        "            if len(idx_wrong_predictions) > 0:\n",
        "                converted_lst = tokenizer.batch_decode(data['ids'], skip_special_tokens=True)\n",
        "                for i in idx_wrong_predictions:\n",
        "                    wrong_preds.append((converted_lst[i], preds.view(-1).cpu()[i], np.max(outputs[i].cpu().numpy())))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat = confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
        "class_report = classification_report(lbllist.numpy(), predlist.numpy(), output_dict=True, digits=2)\n",
        "print(conf_mat)\n",
        "print(classification_report(lbllist.numpy(), predlist.numpy(), output_dict=False))\n",
        "# Per-class accuracy\n",
        "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
        "print(class_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6ESEpBzTPnd",
        "outputId": "6ee42804-6ea1-4b5a-bbf3-90838e3c709f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[28  0]\n",
            " [ 1 21]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98        28\n",
            "           1       1.00      0.95      0.98        22\n",
            "\n",
            "    accuracy                           0.98        50\n",
            "   macro avg       0.98      0.98      0.98        50\n",
            "weighted avg       0.98      0.98      0.98        50\n",
            "\n",
            "[100.          95.45454545]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(how_confident)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpH82oOBvMCi",
        "outputId": "2ac5817f-5495-4336-ae8c-f5e5d109fb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9936663"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "sGEMkJPsHNXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/covid_checkpoint.pth', _use_new_zipfile_serialization=False)"
      ],
      "metadata": {
        "id": "S7whmtxcHTat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Reports"
      ],
      "metadata": {
        "id": "DoOnoOEaHYxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_report_df = pd.DataFrame(class_report).iloc[:-1, :].T\n",
        "class_report_df = class_report_df.round(2)\n",
        "# class_report_df.to_latex('/content/drive/MyDrive/latex/classification_report.tex')"
      ],
      "metadata": {
        "id": "5Nf4ug-yYOos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_rob_f1 = class_report['weighted avg']['f1-score']\n",
        "cov_rob_acc = class_report['accuracy']"
      ],
      "metadata": {
        "id": "aTDBzymQjBWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFRZ2bryKprl",
        "outputId": "92b5de45-9639-402e-cefb-b040357f123d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\"Guys, the covid is not a joke or a fiction. It is surprising that in the second year of the pandemic, people still need to be convinced of this,\" he said, calling on medical colleagues to \"start talking in a frank and unadorned way to our compatriots.\".',\n",
              "  tensor(1),\n",
              "  0.81678647),\n",
              " ('Under no circumstances is the covid simply going to disappear this summer.',\n",
              "  tensor(1),\n",
              "  0.5245222),\n",
              " ('These case declines are very welcome, but are taking place against a backdrop of very high viral transmission.',\n",
              "  tensor(1),\n",
              "  0.5646877),\n",
              " ('Although the first dose provides \"some degree of protection,\" the second dose multiplies the level of protection by a factor of 10.',\n",
              "  tensor(0),\n",
              "  0.829488)]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the big models"
      ],
      "metadata": {
        "id": "VdTPa7X9RwgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer"
      ],
      "metadata": {
        "id": "66F4EUGPRzXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"siebert/sentiment-roberta-large-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "5_9UKaHqXAV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDataset:\n",
        "    def __init__(self, tokenized_texts):\n",
        "        self.tokenized_texts = tokenized_texts\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_texts[\"input_ids\"])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {k: v[idx] for k, v in self.tokenized_texts.items()}"
      ],
      "metadata": {
        "id": "xsQwhNKcXu0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_texts = test_data.Sentence.astype('str').tolist()"
      ],
      "metadata": {
        "id": "2QMsQxF7XRgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts = tokenizer(pred_texts,truncation=True,padding=True)\n",
        "pred_dataset = SimpleDataset(tokenized_texts)"
      ],
      "metadata": {
        "id": "Btv1kitgXAeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# boiler plate syntax. \n",
        "trainer = Trainer(model=model)\n",
        "predictions = trainer.predict(pred_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "cIjt7nA3YF-P",
        "outputId": "0e930490-c038-4820-8305-47d933983713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 90\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12/12 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform predictions to labels\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "labels = pd.Series(preds).map(model.config.id2label)\n",
        "scores = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True)).max(1)"
      ],
      "metadata": {
        "id": "wvnqqBYRXAo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame with texts, predictions, labels, and scores\n",
        "t_df = pd.DataFrame(list(zip(pred_texts,preds,scores)), columns=['text','pred','score'])\n",
        "t_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dO_t_RzbZs-n",
        "outputId": "69df95f0-933a-4612-8630-9f119418eb9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  pred     score\n",
              "0  Countys milestone comes after it hit 4,000 dea...     1  0.995588\n",
              "1  Most projected that COVID-19 cases would conti...     1  0.986337\n",
              "2  Since COVID-19 vaccines became widely availabl...     0  0.987297\n",
              "3  Just 2.1 million people had received their fir...     0  0.997878\n",
              "4  ''In places like the U.S. and the U.K., where ...     0  0.993721"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-803c9719-eae0-4f48-9b93-07b9db7f1dc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>pred</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Countys milestone comes after it hit 4,000 dea...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Most projected that COVID-19 cases would conti...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.986337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Since COVID-19 vaccines became widely availabl...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.987297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Just 2.1 million people had received their fir...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.997878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>''In places like the U.S. and the U.K., where ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.993721</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-803c9719-eae0-4f48-9b93-07b9db7f1dc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-803c9719-eae0-4f48-9b93-07b9db7f1dc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-803c9719-eae0-4f48-9b93-07b9db7f1dc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_df = pd.concat((test_data.Label, t_df),axis=1)"
      ],
      "metadata": {
        "id": "7EXMZ9_KZ6dY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(t_df.Label, t_df.pred)\n",
        "class_report = classification_report(t_df.Label, t_df.pred, output_dict=True, digits=2)\n",
        "print(conf_mat)\n",
        "print(classification_report(t_df.Label, t_df.pred, output_dict=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp5IAFlZaQv-",
        "outputId": "f525ecc9-6359-49b9-a929-8c43a4555f86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[32 18]\n",
            " [ 7 33]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.82      0.64      0.72        50\n",
            "         1.0       0.65      0.82      0.73        40\n",
            "\n",
            "    accuracy                           0.72        90\n",
            "   macro avg       0.73      0.73      0.72        90\n",
            "weighted avg       0.74      0.72      0.72        90\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rob_f1 = class_report['weighted avg']['f1-score']\n",
        "rob_acc = class_report['accuracy']"
      ],
      "metadata": {
        "id": "8FSZigTBi7H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT SENTIMENT**"
      ],
      "metadata": {
        "id": "D8OCt3M0eccL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "id": "zh3O-YnMf3E_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_pred = []\n",
        "bert_score = []\n",
        "for i in pred_texts:\n",
        "    pred = pipe(i)[0]\n",
        "    bert_pred.append(pred['label'])\n",
        "    bert_score.append(pred['score'])\n",
        "bert_pred = (np.array(bert_pred) =='POSITIVE').astype('int')"
      ],
      "metadata": {
        "id": "h-6RnbCRf93w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(t_df.Label, bert_pred)\n",
        "class_report = classification_report(t_df.Label, bert_pred, output_dict=True, digits=2)\n",
        "print(conf_mat)\n",
        "print(classification_report(t_df.Label, bert_pred, output_dict=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcfuVU2cgdlI",
        "outputId": "52b2883f-2832-4e0d-df68-fce0522c044c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[42  8]\n",
            " [25 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.63      0.84      0.72        50\n",
            "         1.0       0.65      0.38      0.48        40\n",
            "\n",
            "    accuracy                           0.63        90\n",
            "   macro avg       0.64      0.61      0.60        90\n",
            "weighted avg       0.64      0.63      0.61        90\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_f1 = class_report['weighted avg']['f1-score']\n",
        "bert_acc = class_report['accuracy']"
      ],
      "metadata": {
        "id": "2QruP_HPi4H0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Vader Sentiment**"
      ],
      "metadata": {
        "id": "cHlYIsVpeZWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XxU4tyTbWF6",
        "outputId": "864f2a13-5fa0-4244-bbf6-adefb3804636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "metadata": {
        "id": "9CpKC9r3bTLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_scores(sentence):\n",
        " \n",
        "    # Create a SentimentIntensityAnalyzer object.\n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "    # decide sentiment as positive, negative and neutral\n",
        "    if sentiment_dict['compound'] >= 0.05 :\n",
        "        return 1\n",
        " \n",
        "    elif sentiment_dict['compound'] <= - 0.05 :\n",
        "        return 0\n",
        " \n",
        "    else:\n",
        "        return np.random.choice([0,1])"
      ],
      "metadata": {
        "id": "o9cXCVsGbTA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vader_pred = []\n",
        "for sent in pred_texts:\n",
        "    vader_pred.append(sentiment_scores(sent))"
      ],
      "metadata": {
        "id": "O-XHE1opbS2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(t_df.Label, vader_pred)\n",
        "class_report = classification_report(t_df.Label, vader_pred, output_dict=True, digits=2)\n",
        "print(conf_mat)\n",
        "print(classification_report(t_df.Label, vader_pred, output_dict=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKEnXXB3d7Tx",
        "outputId": "5a5e491c-14b4-453e-cbcf-9b53ecb2c275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[27 23]\n",
            " [ 9 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.54      0.63        50\n",
            "         1.0       0.57      0.78      0.66        40\n",
            "\n",
            "    accuracy                           0.64        90\n",
            "   macro avg       0.66      0.66      0.64        90\n",
            "weighted avg       0.67      0.64      0.64        90\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vader_f1 = class_report['weighted avg']['f1-score']\n",
        "vader_acc = class_report['accuracy']"
      ],
      "metadata": {
        "id": "mlwoUe2zeU0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combining all classification reports together**"
      ],
      "metadata": {
        "id": "nmz9FXUQq958"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f1_scores = {'Fine-tuned RoBERTa': [cov_rob_f1,cov_rob_acc] , 'Vader': [vader_f1,vader_acc], 'Distil BERT': [bert_f1,bert_acc] ,'RoBERTa Base': [rob_f1, rob_acc]}\n",
        "# acc_scores = {'Fine-tuned RoBERTa': cov_rob_acc, 'Vader': vader_acc, 'Distil BERT': bert_acc ,'Base RoBERTa': rob_acc}\n",
        "compare_scores = pd.DataFrame(f1_scores).round(3)\n",
        "compare_scores.index = ['F1 Score', 'Accuracy Score']\n",
        "compare_scores = compare_scores.T\n",
        "compare_scores"
      ],
      "metadata": {
        "id": "JHseYa-grB7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_scores.to_latex('/content/drive/MyDrive/latex/classification_comparison.tex')"
      ],
      "metadata": {
        "id": "OoIgNFm3sYEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing model on individual cases"
      ],
      "metadata": {
        "id": "YCCj5HC10vru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load('/content/drive/MyDrive/covid_checkpoint.pth', map_location=device)\n",
        "model = RobertaClassifier().to(device)\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "YnV06YHVv-Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing_set = SentimentData(test_data, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "id": "-k2FgBkj0qOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example1 = df['Sentence'][0]\n",
        "example1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XvZKqq9XHYdL",
        "outputId": "f1c89d5b-09d4-47ae-ea16-fe75dc7564b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Countys milestone comes after it hit 4,000 deaths in March.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_prediction(sentence, tokenizer):\n",
        "    \"\"\" Takes in a sentence and returns a single predicted value.\n",
        "    \"\"\"\n",
        "    with torch.no_grad(): \n",
        "        encoded_review = tokenizer.encode_plus(\n",
        "            sentence,\n",
        "            add_special_tokens=True,\n",
        "            max_length=250,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors='pt'\n",
        "            )\n",
        "                \n",
        "        input_ids = encoded_review['input_ids'].to(device)\n",
        "        attention_mask = encoded_review['attention_mask'].to(device)\n",
        "        token_type_ids = encoded_review[\"token_type_ids\"].to(device)\n",
        "        outputs = F.softmax(model(input_ids, attention_mask, token_type_ids), dim=-1)\n",
        "        \n",
        "        predicted_index = np.argmax(outputs[0].cpu().numpy())\n",
        "        predict = {'prediction':predicted_index, 'score': outputs[0].cpu().numpy()[predicted_index]}\n",
        "        return predict"
      ],
      "metadata": {
        "id": "8qe8Kk2XuF_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compare the pipeline trainer api model with the one from PyTorch**"
      ],
      "metadata": {
        "id": "C6GplmV64Hgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = 'while hopes are rising that a rapid rollout of covid vaccines is helping to tame the pandemic in the united states, in much of the world the virus is still surging.'\n",
        "test_sentence = 'the country, which was regularly recording more than 200,000 new cases a day in january, has administered at least one dose of vaccine to more than half of adults and has averaged between 50,000 and 70,000 cases a day since mid-february'\n",
        "test_sentence = 'the country, which was regularly recording more than 200,000 new cases a day in january, is now averaging less cases between 50,000 and 70,000 cases a day since mid-february'\n",
        "test_sentence = 'globally, deaths have risen sharply this spring, but less so than cases, partly due to vaccine campaigns targeting those most vulnerable to covid, such as the elderly'\n",
        "test_sentence = 'Daily vaccination rates have fallen to about 2.5 million doses a day, down from 3 million.'\n",
        "test_sentence = 'Covid testing rates have increased.'\n",
        "\n",
        "test_lowpr = 'Larry Dubinski, president and chief executive officer of the institute, said the newest award recipients are being recognized at a moment when rigorous science is as important as ever. “These achievements come at a critical time for us all,” he said.'"
      ],
      "metadata": {
        "id": "-EPnC3KA80Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = 'Seis millones de residentes de nuestra ciudad han sido vacunados hasta ahora. Y esa es la razón por la que el covid ha disminuido.'\n",
        "print(sentiment_prediction(test, tokenizer))\n",
        "# print(pipe(test_sentence))"
      ],
      "metadata": {
        "id": "SKIBIsjDdupW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b925b1-8da1-4c2d-abed-57df2e107f36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'prediction': 1, 'score': 0.7479823}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = 'Vaccine rates are increasing. But delta is already here.'\n",
        "# test_sentence = 'Vaccine rates are increasing. But more are on the way.'\n",
        "\n",
        "print(sentiment_prediction(test_sentence, tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "SNvagSaVMbmF",
        "outputId": "bdd44989-9ba7-4f9b-934b-196d80f869f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-007119400d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# test_sentence = 'Vaccine rates are increasing. But more are on the way.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentiment_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-80-2b69a022351e>\u001b[0m in \u001b[0;36msentiment_prediction\u001b[0;34m(sentence, tokenizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_review\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_review\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_type_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mpredicted_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpredicted_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1816\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1818\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1819\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SequenceClassifierOutput' object has no attribute 'softmax'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_prediction(test_sentence, tokenizer))\n",
        "print(pipe(test_sentence))"
      ],
      "metadata": {
        "id": "h8ebN1Mz-0vz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}